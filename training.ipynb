{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682a3961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:28:32.683645Z",
     "iopub.status.busy": "2026-01-10T12:28:32.683347Z",
     "iopub.status.idle": "2026-01-10T12:28:33.432471Z",
     "shell.execute_reply": "2026-01-10T12:28:33.431388Z"
    },
    "papermill": {
     "duration": 0.75407,
     "end_time": "2026-01-10T12:28:33.434095",
     "exception": false,
     "start_time": "2026-01-10T12:28:32.680025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Double-Pendulum-Simulation'...\r\n",
      "remote: Enumerating objects: 420, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (24/24), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 420 (delta 11), reused 16 (delta 7), pack-reused 396 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (420/420), 187.37 KiB | 3.12 MiB/s, done.\r\n",
      "Resolving deltas: 100% (245/245), done.\r\n",
      "Repository cloned successfully!\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "base_path = '/kaggle/working'\n",
    "project_name = 'Double-Pendulum-Simulation'\n",
    "project_root = os.path.join(base_path, project_name)\n",
    "\n",
    "# Clone or pull repository\n",
    "if not os.path.exists(project_root):\n",
    "    os.chdir(base_path)\n",
    "    !git clone https://github.com/nthday-jpg/Double-Pendulum-Simulation.git\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    os.chdir(project_root)\n",
    "    !git pull\n",
    "    print(\"Repository updated successfully!\")\n",
    "%cd {base_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acfbaf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:28:33.439692Z",
     "iopub.status.busy": "2026-01-10T12:28:33.439215Z",
     "iopub.status.idle": "2026-01-10T12:28:38.209685Z",
     "shell.execute_reply": "2026-01-10T12:28:38.208914Z"
    },
    "papermill": {
     "duration": 4.775486,
     "end_time": "2026-01-10T12:28:38.211847",
     "exception": false,
     "start_time": "2026-01-10T12:28:33.436361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 trajectories...\r\n",
      "Deriving equations symbolically (this may take a moment)...\r\n",
      "Symbolic derivation complete!\r\n",
      "  Trajectory 000 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\r\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_000.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_000.json\r\n",
      "\r\n",
      "Dataset complete! Saved to /kaggle/working/Double-Pendulum-Simulation/data/raw\r\n"
     ]
    }
   ],
   "source": [
    "# Generate training data\n",
    "# Generate 10 trajectories with 5000 points each\n",
    "!python {project_root}/generate_data.py \\\n",
    "    --output_dir {project_root}/data/raw \\\n",
    "    --num_trajectories 1 \\\n",
    "    --num_points 3000 \\\n",
    "    --t_start 0.0 \\\n",
    "    --t_end 5.0 \\\n",
    "    --check_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7722e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:28:38.217560Z",
     "iopub.status.busy": "2026-01-10T12:28:38.217278Z",
     "iopub.status.idle": "2026-01-10T12:28:38.339965Z",
     "shell.execute_reply": "2026-01-10T12:28:38.338868Z"
    },
    "papermill": {
     "duration": 0.12773,
     "end_time": "2026-01-10T12:28:38.341818",
     "exception": false,
     "start_time": "2026-01-10T12:28:38.214088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove old dataset\n",
    "!rm -rf /kaggle/working/Double-Pendulum-Simulation/data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368af10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:28:38.348546Z",
     "iopub.status.busy": "2026-01-10T12:28:38.348264Z",
     "iopub.status.idle": "2026-01-10T12:28:38.361374Z",
     "shell.execute_reply": "2026-01-10T12:28:38.360605Z"
    },
    "papermill": {
     "duration": 0.018811,
     "end_time": "2026-01-10T12:28:38.363040",
     "exception": false,
     "start_time": "2026-01-10T12:28:38.344229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Seed: 42\n",
      "  Model: pinn, Hidden: 64 64, Activation: tanh\n",
      "  Optimizer: adam, LR: 0.001, Weight Decay: 0.0\n",
      "  Epochs: 200, Early Stop: 50\n",
      "  Batch sizes: data=128, colloc=1024\n",
      "  Data loss ratio = 0.999, type=lagrangian\n",
      "  Checkpoint: run_20260110_113642/checkpoints/best_model.pth\n",
      "\n",
      "Command arguments generated with 41 parameters\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration\n",
    "# Experiment\n",
    "seed = 42\n",
    "run_name = None  # Auto-generated if None\n",
    "checkpoint_path = \"run_20260110_113642/checkpoints/best_model.pth\"\n",
    "\n",
    "# Data\n",
    "data_dir = f\"{project_root}/data/raw\"\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "normalize_time = False\n",
    "normalize_state = False\n",
    "\n",
    "# Model Architecture\n",
    "model = \"pinn\"  # mlp | neural_ode | hnn | pinn\n",
    "hidden_dims = \"64 64\"  # Space-separated\n",
    "activation = \"tanh\"  # tanh | relu | gelu | silu | softplus\n",
    "use_batch_norm = False\n",
    "dropout_rate = 0.0\n",
    "final_activation = None  # None | tanh | sigmoid\n",
    "input_dim = 5\n",
    "output_dim = 2\n",
    "\n",
    "# Training\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "batch_size_collocation = 1024\n",
    "epochs = 200\n",
    "optimizer = \"adam\"  # adam | adamw | sgd\n",
    "weight_decay = 0.0\n",
    "grad_clip = None\n",
    "scheduler = None  # None | cosine | step\n",
    "\n",
    "# PyTorch Optimizations\n",
    "use_compile = False\n",
    "compile_mode = \"default\"  # default | reduce-overhead | max-autotune\n",
    "mixed_precision = False\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Regularization\n",
    "l1_lambda = 0.0\n",
    "l2_lambda = 0.0\n",
    "\n",
    "# Physics / PINN\n",
    "use_physics = True\n",
    "n_collocation = 5000\n",
    "data_fraction = 0.1\n",
    "data_loss_ratio = 0.999\n",
    "residual_type = \"lagrangian\"  # eom | lagrangian | hamiltonian\n",
    "\n",
    "# Time Domain\n",
    "t_min = 0.0\n",
    "t_max = 5.0\n",
    "collocation_sampling = \"uniform\"  # uniform | random | latin_hypercube\n",
    "\n",
    "# Rollout Evaluation\n",
    "rollout_T = 5.0\n",
    "rollout_dt = 0.01\n",
    "\n",
    "# Logging\n",
    "log_interval = 10\n",
    "print_interval = 10\n",
    "save_checkpoints = True\n",
    "checkpoint_interval = 50\n",
    "test_interval = 50\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping_patience = 50  # None to disable\n",
    "\n",
    "# Physical Parameters\n",
    "m1 = 1.0\n",
    "m2 = 1.0\n",
    "l1 = 1.0\n",
    "l2 = 1.0\n",
    "g = 9.81\n",
    "\n",
    "# Build command arguments\n",
    "args_list = [\n",
    "    f\"--seed {seed}\",\n",
    "    f\"--hidden_dims {hidden_dims}\",\n",
    "    f\"--input_dim {input_dim}\",\n",
    "    f\"--output_dim {output_dim}\",\n",
    "    f\"--residual_type {residual_type}\",\n",
    "    f\"--t_max {t_max}\",\n",
    "    f\"--t_min {t_min}\",\n",
    "    f\"--epochs {epochs}\",\n",
    "    f\"--lr {lr}\",\n",
    "    f\"--batch_size {batch_size}\",\n",
    "    f\"--batch_size_collocation {batch_size_collocation}\",\n",
    "    f\"--data_dir {data_dir}\",\n",
    "    f\"--val_split {val_split}\",\n",
    "    f\"--test_split {test_split}\",\n",
    "    f\"--model {model}\",\n",
    "    f\"--activation {activation}\",\n",
    "    f\"--dropout_rate {dropout_rate}\",\n",
    "    f\"--optimizer {optimizer}\",\n",
    "    f\"--weight_decay {weight_decay}\",\n",
    "    f\"--compile_mode {compile_mode}\",\n",
    "    f\"--gradient_accumulation_steps {gradient_accumulation_steps}\",\n",
    "    f\"--l1_lambda {l1_lambda}\",\n",
    "    f\"--l2_lambda {l2_lambda}\",\n",
    "    f\"--n_collocation {n_collocation}\",\n",
    "    f\"--data_fraction {data_fraction}\",\n",
    "    f\"--data_loss_ratio {data_loss_ratio}\",\n",
    "    f\"--collocation_sampling {collocation_sampling}\",\n",
    "    f\"--rollout_T {rollout_T}\",\n",
    "    f\"--rollout_dt {rollout_dt}\",\n",
    "    f\"--log_interval {log_interval}\",\n",
    "    f\"--print_interval {print_interval}\",\n",
    "    f\"--test_interval {test_interval}\",\n",
    "    f\"--checkpoint_interval {checkpoint_interval}\",\n",
    "    f\"--m1 {m1}\",\n",
    "    f\"--m2 {m2}\",\n",
    "    f\"--l1 {l1}\",\n",
    "    f\"--l2 {l2}\",\n",
    "    f\"--g {g}\"\n",
    "]\n",
    "\n",
    "# Add optional flags\n",
    "if run_name:\n",
    "    args_list.append(f\"--run_name {run_name}\")\n",
    "if checkpoint_path:\n",
    "    args_list.append(f\"--checkpoint_path {checkpoint_path}\")\n",
    "if use_compile:\n",
    "    args_list.append(\"--use_compile\")\n",
    "if normalize_time:\n",
    "    args_list.append(\"--normalize_time\")\n",
    "if normalize_state:\n",
    "    args_list.append(\"--normalize_state\")\n",
    "if use_batch_norm:\n",
    "    args_list.append(\"--use_batch_norm\")\n",
    "if final_activation:\n",
    "    args_list.append(f\"--final_activation {final_activation}\")\n",
    "if grad_clip:\n",
    "    args_list.append(f\"--grad_clip {grad_clip}\")\n",
    "if scheduler:\n",
    "    args_list.append(f\"--scheduler {scheduler}\")\n",
    "if mixed_precision:\n",
    "    args_list.append(\"--mixed_precision\")\n",
    "if save_checkpoints:\n",
    "    args_list.append(\"--save_checkpoints\")\n",
    "if early_stopping_patience:\n",
    "    args_list.append(f\"--early_stopping_patience {early_stopping_patience}\")\n",
    "if use_physics:\n",
    "    args_list.append(\"--use_physics\")\n",
    "\n",
    "args = \" \".join(args_list)\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Seed: {seed}\")\n",
    "print(f\"  Model: {model}, Hidden: {hidden_dims}, Activation: {activation}\")\n",
    "print(f\"  Optimizer: {optimizer}, LR: {lr}, Weight Decay: {weight_decay}\")\n",
    "print(f\"  Epochs: {epochs}, Early Stop: {early_stopping_patience if early_stopping_patience else 'disabled'}\")\n",
    "print(f\"  Batch sizes: data={batch_size}, colloc={batch_size_collocation}\")\n",
    "print(f\"  Data loss ratio = {data_loss_ratio}, type={residual_type}\")\n",
    "print(f\"  Checkpoint: {checkpoint_path if checkpoint_path else 'None (training from scratch)'}\")\n",
    "print(f\"\\nCommand arguments generated with {len(args_list)} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0632a621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:28:38.367820Z",
     "iopub.status.busy": "2026-01-10T12:28:38.367586Z",
     "iopub.status.idle": "2026-01-10T12:29:16.648578Z",
     "shell.execute_reply": "2026-01-10T12:29:16.647613Z"
    },
    "papermill": {
     "duration": 38.285609,
     "end_time": "2026-01-10T12:29:16.650642",
     "exception": false,
     "start_time": "2026-01-10T12:28:38.365033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\r\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\r\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\r\n",
      "\t`--num_machines` was set to a value of `1`\r\n",
      "\t`--mixed_precision` was set to a value of `'no'`\r\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\r\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1768048139.992601      84 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1768048139.992581      83 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1768048140.044396      83 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1768048140.044401      84 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0000 00:00:1768048140.456146      84 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768048140.456146      83 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768048140.456219      84 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768048140.456224      84 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768048140.456226      83 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768048140.456228      84 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768048140.456234      83 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768048140.456243      83 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "ðŸŒ± Random seed set to: 42\r\n",
      "ðŸŒ± Random seed set to: 42\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/train.py\", line 313, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/train.py\", line 291, in main\r\n",
      "    data_loader, colloc_loader, val_loader, test_loader = get_dataloader(\r\n",
      "                                                          ^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/data/dataset.py\", line 154, in get_dataloader\r\n",
      "    data_dataset = PendulumDataset(data_dir)\r\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/data/dataset.py\", line 32, in __init__\r\n",
      "    trajectory_files = sorted([f for f in os.listdir(data_dir) if f.startswith('trajectory_') and f.endswith('.npz')])\r\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/Double-Pendulum-Simulation/data/raw'\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/train.py\", line 313, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/train.py\", line 291, in main\r\n",
      "    data_loader, colloc_loader, val_loader, test_loader = get_dataloader(\r\n",
      "                                                          ^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/data/dataset.py\", line 154, in get_dataloader\r\n",
      "    data_dataset = PendulumDataset(data_dir)\r\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/Double-Pendulum-Simulation/data/dataset.py\", line 32, in __init__\r\n",
      "    trajectory_files = sorted([f for f in os.listdir(data_dir) if f.startswith('trajectory_') and f.endswith('.npz')])\r\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/Double-Pendulum-Simulation/data/raw'\r\n",
      "W0110 12:29:15.460000 64 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 84 closing signal SIGTERM\r\n",
      "E0110 12:29:15.476000 64 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 83) of binary: /usr/bin/python3\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/accelerate\", line 10, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "             ^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1226, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 853, in multi_gpu_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py\", line 892, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 143, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 277, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "/kaggle/working/Double-Pendulum-Simulation/train.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "  <NO_OTHER_FAILURES>\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2026-01-10_12:29:15\r\n",
      "  host      : dc6a51b721c2\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 83)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "# Launch distributed training with Accelerate\n",
    "!accelerate launch --num_processes=2 {project_root}/train.py {args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64aae487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:29:16.657513Z",
     "iopub.status.busy": "2026-01-10T12:29:16.657236Z",
     "iopub.status.idle": "2026-01-10T12:29:16.775113Z",
     "shell.execute_reply": "2026-01-10T12:29:16.774475Z"
    },
    "papermill": {
     "duration": 0.123159,
     "end_time": "2026-01-10T12:29:16.776566",
     "exception": false,
     "start_time": "2026-01-10T12:29:16.653407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: runs\r\n",
      "\r\n",
      "zip error: Nothing to do! (try: zip -r /kaggle/working/runs.zip . -i runs)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/runs.zip runs\n",
    "# !rm -rf runs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9214451,
     "sourceId": 14444996,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.911358,
   "end_time": "2026-01-10T12:29:16.996031",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-10T12:28:30.084673",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
