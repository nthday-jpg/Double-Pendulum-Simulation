{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a3961",
   "metadata": {
    "papermill": {
     "duration": 0.75407,
     "end_time": "2026-01-10T12:28:33.434095",
     "exception": false,
     "start_time": "2026-01-10T12:28:32.680025",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "base_path = '/kaggle/working'\n",
    "project_name = 'Double-Pendulum-Simulation'\n",
    "project_root = os.path.join(base_path, project_name)\n",
    "\n",
    "# Clone or pull repository\n",
    "if not os.path.exists(project_root):\n",
    "    os.chdir(base_path)\n",
    "    !git clone https://github.com/nthday-jpg/Double-Pendulum-Simulation.git\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    os.chdir(project_root)\n",
    "    !git pull\n",
    "    print(\"Repository updated successfully!\")\n",
    "%cd {base_path}\n",
    "\n",
    "# Ensure project root is in PYTHONPATH for script's imports\n",
    "os.environ['PYTHONPATH'] = project_root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfbaf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:24:49.980413Z",
     "iopub.status.busy": "2026-01-12T15:24:49.980107Z",
     "iopub.status.idle": "2026-01-12T15:24:52.634604Z",
     "shell.execute_reply": "2026-01-12T15:24:52.633917Z",
     "shell.execute_reply.started": "2026-01-12T15:24:49.980384Z"
    },
    "papermill": {
     "duration": 4.775486,
     "end_time": "2026-01-10T12:28:38.211847",
     "exception": false,
     "start_time": "2026-01-10T12:28:33.436361",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 20 trajectories...\n",
      "Deriving equations symbolically (this may take a moment)...\n",
      "Symbolic derivation complete!\n",
      "  Trajectory 000 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_000.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_000.json\n",
      "  Trajectory 001 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_001.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_001.json\n",
      "  Trajectory 002 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_002.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_002.json\n",
      "  Trajectory 003 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_003.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_003.json\n",
      "  Trajectory 004 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_004.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_004.json\n",
      "  Trajectory 005 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_005.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_005.json\n",
      "  Trajectory 006 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_006.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_006.json\n",
      "  Trajectory 007 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_007.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_007.json\n",
      "  Trajectory 008 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_008.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_008.json\n",
      "  Trajectory 009 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_009.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_009.json\n",
      "  Trajectory 010 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_010.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_010.json\n",
      "  Trajectory 011 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_011.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_011.json\n",
      "  Trajectory 012 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_012.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_012.json\n",
      "  Trajectory 013 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_013.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_013.json\n",
      "  Trajectory 014 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_014.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_014.json\n",
      "  Trajectory 015 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_015.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_015.json\n",
      "  Trajectory 016 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_016.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_016.json\n",
      "  Trajectory 017 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_017.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_017.json\n",
      "  Trajectory 018 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_018.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_018.json\n",
      "  Trajectory 019 (m1=1.00, m2=1.00, l1=1.00, l2=1.00): Energy drift = 0.000%\n",
      "  Saved: /kaggle/working/Double-Pendulum-Simulation/data/raw/trajectory_019.npz and /kaggle/working/Double-Pendulum-Simulation/data/raw/parameters_019.json\n",
      "\n",
      "Dataset complete! Saved to /kaggle/working/Double-Pendulum-Simulation/data/raw\n"
     ]
    }
   ],
   "source": [
    "!python {project_root}/scripts/generate_data.py \\\n",
    "    --output_dir {project_root}/data/raw \\\n",
    "    --num_trajectories 20 \\\n",
    "    --num_points 3000 \\\n",
    "    --t_start 0.0 \\\n",
    "    --t_end 2.0 \\\n",
    "    --check_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7722e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:28:38.217560Z",
     "iopub.status.busy": "2026-01-10T12:28:38.217278Z",
     "iopub.status.idle": "2026-01-10T12:28:38.339965Z",
     "shell.execute_reply": "2026-01-10T12:28:38.338868Z"
    },
    "papermill": {
     "duration": 0.12773,
     "end_time": "2026-01-10T12:28:38.341818",
     "exception": false,
     "start_time": "2026-01-10T12:28:38.214088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove old dataset\n",
    "!rm -rf /kaggle/working/Double-Pendulum-Simulation/data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368af10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:25:16.800031Z",
     "iopub.status.busy": "2026-01-12T15:25:16.799486Z",
     "iopub.status.idle": "2026-01-12T15:25:16.812723Z",
     "shell.execute_reply": "2026-01-12T15:25:16.811956Z",
     "shell.execute_reply.started": "2026-01-12T15:25:16.800002Z"
    },
    "papermill": {
     "duration": 0.018811,
     "end_time": "2026-01-10T12:28:38.363040",
     "exception": false,
     "start_time": "2026-01-10T12:28:38.344229",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Seed: 42\n",
      "  Model: pinn, Hidden: 64 64 64 64, Activation: tanh\n",
      "  Optimizer: adam, LR: 0.0005, Weight Decay: 0.0\n",
      "  Epochs: 500, Early Stop: 100\n",
      "  Batch sizes: data=128, colloc=1024\n",
      "  Data loss ratio = 0.99, type=lagrangian\n",
      "  Checkpoint: None (training from scratch)\n",
      "\n",
      "Command arguments generated with 42 parameters\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration\n",
    "# Experiment\n",
    "seed = 42\n",
    "run_name = None  # Auto-generated if None\n",
    "checkpoint_path = None#\"runs/run_20260112_135314/checkpoints/best_model.pth\"\n",
    "\n",
    "# Data\n",
    "data_dir = f\"{project_root}/data/raw\"\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "normalize_time = True\n",
    "normalize_state = False\n",
    "\n",
    "# Model Architecture\n",
    "model = \"pinn\"  # mlp | neural_ode | hnn | pinn\n",
    "hidden_dims = \"124 124 124 124\"  # Space-separated\n",
    "activation = \"tanh\"  # tanh | relu | gelu | silu | softplus\n",
    "use_batch_norm = False\n",
    "dropout_rate = 0.0\n",
    "final_activation = None  # None | tanh | sigmoid\n",
    "input_dim = 5\n",
    "output_dim = 2\n",
    "\n",
    "# Training\n",
    "lr = 0.0005\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "optimizer = \"adam\"  # adam | adamw | sgd\n",
    "weight_decay = 0.0\n",
    "grad_clip = None\n",
    "scheduler = None  # None | cosine | step\n",
    "\n",
    "# PyTorch Optimizations\n",
    "use_compile = False\n",
    "compile_mode = \"default\"  # default | reduce-overhead | max-autotune\n",
    "mixed_precision = False\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Regularization\n",
    "l1_lambda = 0.0\n",
    "l2_lambda = 0.001\n",
    "\n",
    "# Physics / PINN\n",
    "data_loss_ratio = 0.99\n",
    "residual_type = \"lagrangian\"  # eom | lagrangian | hamiltonian\n",
    "\n",
    "# Logging\n",
    "log_interval = 10\n",
    "print_interval = 50\n",
    "save_checkpoints = True\n",
    "checkpoint_interval = 50\n",
    "test_interval = 100\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping_patience = 100  # None to disable\n",
    "\n",
    "# Physical Parameters\n",
    "m1 = 1.0\n",
    "m2 = 1.0\n",
    "l1 = 1.0\n",
    "l2 = 1.0\n",
    "g = 9.81\n",
    "\n",
    "# Build command arguments\n",
    "args_list = [\n",
    "    f\"--seed {seed}\",\n",
    "    f\"--hidden_dims {hidden_dims}\",\n",
    "    f\"--input_dim {input_dim}\",\n",
    "    f\"--output_dim {output_dim}\",\n",
    "    f\"--residual_type {residual_type}\",\n",
    "    f\"--epochs {epochs}\",\n",
    "    f\"--lr {lr}\",\n",
    "    f\"--batch_size {batch_size}\",\n",
    "    f\"--data_dir {data_dir}\",\n",
    "    f\"--val_split {val_split}\",\n",
    "    f\"--test_split {test_split}\",\n",
    "    f\"--model {model}\",\n",
    "    f\"--activation {activation}\",\n",
    "    f\"--dropout_rate {dropout_rate}\",\n",
    "    f\"--optimizer {optimizer}\",\n",
    "    f\"--weight_decay {weight_decay}\",\n",
    "    f\"--compile_mode {compile_mode}\",\n",
    "    f\"--gradient_accumulation_steps {gradient_accumulation_steps}\",\n",
    "    f\"--l1_lambda {l1_lambda}\",\n",
    "    f\"--l2_lambda {l2_lambda}\",\n",
    "    f\"--data_loss_ratio {data_loss_ratio}\",\n",
    "    f\"--log_interval {log_interval}\",\n",
    "    f\"--print_interval {print_interval}\",\n",
    "    f\"--test_interval {test_interval}\",\n",
    "    f\"--checkpoint_interval {checkpoint_interval}\",\n",
    "    f\"--m1 {m1}\",\n",
    "    f\"--m2 {m2}\",\n",
    "    f\"--l1 {l1}\",\n",
    "    f\"--l2 {l2}\",\n",
    "    f\"--g {g}\"\n",
    "]\n",
    "\n",
    "# Add optional flags\n",
    "if run_name:\n",
    "    args_list.append(f\"--run_name {run_name}\")\n",
    "if checkpoint_path:\n",
    "    args_list.append(f\"--checkpoint_path {checkpoint_path}\")\n",
    "if use_compile:\n",
    "    args_list.append(\"--use_compile\")\n",
    "if normalize_time:\n",
    "    args_list.append(\"--normalize_time\")\n",
    "if normalize_state:\n",
    "    args_list.append(\"--normalize_state\")\n",
    "if use_batch_norm:\n",
    "    args_list.append(\"--use_batch_norm\")\n",
    "if final_activation:\n",
    "    args_list.append(f\"--final_activation {final_activation}\")\n",
    "if grad_clip:\n",
    "    args_list.append(f\"--grad_clip {grad_clip}\")\n",
    "if scheduler:\n",
    "    args_list.append(f\"--scheduler {scheduler}\")\n",
    "if mixed_precision:\n",
    "    args_list.append(\"--mixed_precision\")\n",
    "if save_checkpoints:\n",
    "    args_list.append(\"--save_checkpoints\")\n",
    "if early_stopping_patience:\n",
    "    args_list.append(f\"--early_stopping_patience {early_stopping_patience}\")\n",
    "\n",
    "args = \" \".join(args_list)\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Seed: {seed}\")\n",
    "print(f\"  Model: {model}, Hidden: {hidden_dims}, Activation: {activation}\")\n",
    "print(f\"  Optimizer: {optimizer}, LR: {lr}, Weight Decay: {weight_decay}\")\n",
    "print(f\"  Epochs: {epochs}, Early Stop: {early_stopping_patience if early_stopping_patience else 'disabled'}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Data loss ratio = {data_loss_ratio}, type={residual_type}\")\n",
    "print(f\"  Checkpoint: {checkpoint_path if checkpoint_path else 'None (training from scratch)'}\")\n",
    "print(f\"\\nCommand arguments generated with {len(args_list)} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632a621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:25:21.987510Z",
     "iopub.status.busy": "2026-01-12T15:25:21.986956Z",
     "iopub.status.idle": "2026-01-12T15:56:40.547912Z",
     "shell.execute_reply": "2026-01-12T15:56:40.547198Z",
     "shell.execute_reply.started": "2026-01-12T15:25:21.987481Z"
    },
    "papermill": {
     "duration": 38.285609,
     "end_time": "2026-01-10T12:29:16.650642",
     "exception": false,
     "start_time": "2026-01-10T12:28:38.365033",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768231532.552036  221803 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768231532.552047  221804 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768231532.558683  221804 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1768231532.558684  221803 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768231532.576115  221804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768231532.576109  221803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768231532.576142  221804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768231532.576147  221803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768231532.576151  221804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768231532.576154  221803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768231532.576159  221804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768231532.576165  221803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "ðŸŒ± Random seed set to: 42\n",
      "ðŸŒ± Random seed set to: 42\n",
      "ðŸ“Š Loaded 20 trajectories with shared parameters, 60000 total data points\n",
      "ðŸ“Š Loaded 20 trajectories with shared parameters, 60000 total data points\n",
      "DataLoaders: data_bs=128, colloc_bs=1024, workers=4\n",
      "Dataset splits: train=43200, val=10800, test=6000 (late time)\n",
      "Temporal split: train/val use first 90% of time, test uses last 10%\n",
      "[W112 15:25:36.273067198 Utils.hpp:166] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())\n",
      "[W112 15:25:36.273094324 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "DataLoaders: data_bs=128, colloc_bs=1024, workers=4\n",
      "Dataset splits: train=43200, val=10800, test=6000 (late time)\n",
      "Temporal split: train/val use first 90% of time, test uses last 10%\n",
      "[W112 15:25:36.283853251 Utils.hpp:166] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())\n",
      "[W112 15:25:36.283874064 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "NCCL version 2.27.3+cuda12.9\n",
      "[rank0]:[W112 15:25:37.885317837 Utils.hpp:112] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())\n",
      "[rank1]:[W112 15:25:37.887528454 Utils.hpp:112] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())\n",
      "ðŸ“Š Logging to: runs/run_20260112_152535\n",
      "============================================================\n",
      "Starting training for 500 epochs...\n",
      "Device: cuda:0\n",
      "Data batch: 128, Collocation batch: 1024\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "Epoch           1/500\n",
      "================================================================================\n",
      "Dataset         Total Loss      Physics Loss    Data Loss      \n",
      "--------------------------------------------------------------------------------\n",
      "Train           0.068346        0.781412        0.061143       \n",
      "Validation      0.514008        0.911209        0.509996       \n",
      "================================================================================\n",
      "\n",
      "  â†’ New best model saved (val_loss: 0.514008)\n",
      "  â†’ New best model saved (val_loss: 0.421336)\n",
      "  â†’ New best model saved (val_loss: 0.395632)\n",
      "  â†’ New best model saved (val_loss: 0.384820)\n",
      "  â†’ New best model saved (val_loss: 0.365204)\n",
      "  â†’ New best model saved (val_loss: 0.360618)\n",
      "  â†’ New best model saved (val_loss: 0.341445)\n",
      "  â†’ New best model saved (val_loss: 0.330464)\n",
      "  â†’ New best model saved (val_loss: 0.320751)\n",
      "  â†’ New best model saved (val_loss: 0.315647)\n",
      "  â†’ New best model saved (val_loss: 0.307987)\n",
      "  â†’ New best model saved (val_loss: 0.303997)\n",
      "  â†’ New best model saved (val_loss: 0.300176)\n",
      "  â†’ New best model saved (val_loss: 0.296508)\n",
      "  â†’ New best model saved (val_loss: 0.286729)\n",
      "  â†’ New best model saved (val_loss: 0.284119)\n",
      "  â†’ New best model saved (val_loss: 0.282334)\n",
      "  â†’ New best model saved (val_loss: 0.280088)\n",
      "  â†’ New best model saved (val_loss: 0.279114)\n",
      "  â†’ New best model saved (val_loss: 0.276820)\n",
      "  â†’ New best model saved (val_loss: 0.273840)\n",
      "  â†’ New best model saved (val_loss: 0.271697)\n",
      "  â†’ New best model saved (val_loss: 0.265961)\n",
      "  â†’ New best model saved (val_loss: 0.264147)\n",
      "  â†’ New best model saved (val_loss: 0.263411)\n",
      "  â†’ New best model saved (val_loss: 0.262040)\n",
      "  â†’ New best model saved (val_loss: 0.260290)\n",
      "  â†’ New best model saved (val_loss: 0.259664)\n",
      "  â†’ New best model saved (val_loss: 0.258815)\n",
      "  â†’ New best model saved (val_loss: 0.257343)\n",
      "  â†’ New best model saved (val_loss: 0.255228)\n",
      "  â†’ New best model saved (val_loss: 0.252526)\n",
      "  â†’ New best model saved (val_loss: 0.250434)\n",
      "  â†’ New best model saved (val_loss: 0.247290)\n",
      "  â†’ New best model saved (val_loss: 0.244500)\n",
      "  â†’ New best model saved (val_loss: 0.243133)\n",
      "  â†’ New best model saved (val_loss: 0.240066)\n",
      "  â†’ New best model saved (val_loss: 0.239236)\n",
      "\n",
      "================================================================================\n",
      "Epoch           50/500\n",
      "================================================================================\n",
      "Dataset         Total Loss      Physics Loss    Data Loss      \n",
      "--------------------------------------------------------------------------------\n",
      "Train           0.040950        1.600045        0.025201       \n",
      "Validation      0.239983        1.848565        0.223734       \n",
      "================================================================================\n",
      "\n",
      "  â†’ New best model saved (val_loss: 0.239075)\n",
      "  â†’ New best model saved (val_loss: 0.238602)\n",
      "  â†’ New best model saved (val_loss: 0.238304)\n",
      "  â†’ New best model saved (val_loss: 0.237006)\n",
      "  â†’ New best model saved (val_loss: 0.236700)\n",
      "  â†’ New best model saved (val_loss: 0.236188)\n",
      "  â†’ New best model saved (val_loss: 0.236034)\n",
      "  â†’ New best model saved (val_loss: 0.235876)\n",
      "  â†’ New best model saved (val_loss: 0.235771)\n",
      "  â†’ New best model saved (val_loss: 0.234651)\n",
      "  â†’ New best model saved (val_loss: 0.234142)\n",
      "\n",
      "================================================================================\n",
      "Epoch           100/500\n",
      "================================================================================\n",
      "Dataset         Total Loss      Physics Loss    Data Loss      \n",
      "--------------------------------------------------------------------------------\n",
      "Train           0.037966        1.379616        0.024414       \n",
      "Validation      0.237393        1.991590        0.219674       \n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Evaluating on Test Set (Temporal Extrapolation)\n",
      "================================================================================\n",
      "Loading best model from: runs/run_20260112_152535/checkpoints/best_model.pth\n",
      "Evaluating test set...\n",
      "\n",
      "Test Set Results:\n",
      "--------------------------------------------------------------------------------\n",
      "Metric                         Value          \n",
      "--------------------------------------------------------------------------------\n",
      "Total Loss                     2.127770       \n",
      "Physics Loss                   0.769730       \n",
      "Data Loss                      2.141488       \n",
      "================================================================================\n",
      "\n",
      "Test results saved to: runs/run_20260112_152535/test_results.txt\n",
      "  â†’ New best model saved (val_loss: 0.234021)\n",
      "  â†’ New best model saved (val_loss: 0.233929)\n",
      "\n",
      "================================================================================\n",
      "Epoch           150/500\n",
      "================================================================================\n",
      "Dataset         Total Loss      Physics Loss    Data Loss      \n",
      "--------------------------------------------------------------------------------\n",
      "Train           0.037967        1.392385        0.024286       \n",
      "Validation      0.234385        1.956863        0.216986       \n",
      "================================================================================\n",
      "\n",
      "  â†’ New best model saved (val_loss: 0.233800)\n",
      "\n",
      "================================================================================\n",
      "Epoch           200/500\n",
      "================================================================================\n",
      "Dataset         Total Loss      Physics Loss    Data Loss      \n",
      "--------------------------------------------------------------------------------\n",
      "Train           0.037488        1.339005        0.024342       \n",
      "Validation      0.234416        1.827448        0.218325       \n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Evaluating on Test Set (Temporal Extrapolation)\n",
      "================================================================================\n",
      "Loading best model from: runs/run_20260112_152535/checkpoints/best_model.pth\n",
      "Evaluating test set...\n",
      "\n",
      "Test Set Results:\n",
      "--------------------------------------------------------------------------------\n",
      "Metric                         Value          \n",
      "--------------------------------------------------------------------------------\n",
      "Total Loss                     2.152311       \n",
      "Physics Loss                   0.567544       \n",
      "Data Loss                      2.168318       \n",
      "================================================================================\n",
      "\n",
      "Test results saved to: runs/run_20260112_152535/test_results.txt\n",
      "  â†’ New best model saved (val_loss: 0.233779)\n",
      "^C\n",
      "W0112 15:56:39.843000 221784 torch/distributed/elastic/agent/server/api.py:723] Received 2 death signal, shutting down workers\n",
      "W0112 15:56:39.845000 221784 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 221803 closing signal SIGINT\n",
      "W0112 15:56:39.846000 221784 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 221804 closing signal SIGINT\n",
      "Training complete. Logs saved to runs/run_20260112_152535\n",
      "Best model saved at: runs/run_20260112_152535/checkpoints/best_model.pth\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/kaggle/working/Double-Pendulum-Simulation/train.py\", line 317, in <module>\n",
      "[rank1]:     main()\n",
      "[rank1]:   File \"/kaggle/working/Double-Pendulum-Simulation/train.py\", line 313, in main\n",
      "[rank1]:     trainer.train()\n",
      "[rank1]:   File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 113, in train\n",
      "[rank1]:     total_train_loss, total_physics_loss, total_data_loss, total_samples = self._train_step(\n",
      "[rank1]:                                                                            ^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 237, in _train_step\n",
      "[rank1]:     self.accelerator.backward(loss)\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\", line 2740, in backward\n",
      "[rank1]:     loss.backward(**kwargs)\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 647, in backward\n",
      "[rank1]:     torch.autograd.backward(\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "[rank1]:     _engine_run_backward(\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]: KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Launch distributed training with Accelerate\n",
    "!accelerate launch --num_processes=2 {project_root}/scripts/train.py {args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49c89a-1606-4be8-9753-4f316dce322f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:56:48.436625Z",
     "iopub.status.busy": "2026-01-12T15:56:48.436057Z",
     "iopub.status.idle": "2026-01-12T15:56:53.797922Z",
     "shell.execute_reply": "2026-01-12T15:56:53.797240Z",
     "shell.execute_reply.started": "2026-01-12T15:56:48.436590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /kaggle/working/runs/run_20260112_152535/checkpoints/best_model.pth\n",
      "Normalization settings:\n",
      "  Time: True | Range: [0.000, 3.000]\n",
      "  Angles: True | Range: [-3.142, 3.142]\n",
      "\n",
      "Initial state: theta1=0.473, theta2=-0.635, omega1=-0.425, omega2=-0.124\n",
      "Time span: (0.0, 1.0), Points: 1000\n",
      "\n",
      "Simulating with PINN...\n",
      "Saved trajectory: /kaggle/working/runs/test_inference/trajectory_pinn.npz\n",
      "Saved parameters: /kaggle/working/runs/test_inference/trajectory_pinn_parameters.json\n",
      "\n",
      "Computing ground truth...\n",
      "Deriving equations symbolically (this may take a moment)...\n",
      "Symbolic derivation complete!\n",
      "Saved trajectory: /kaggle/working/runs/test_inference/trajectory_true.npz\n",
      "Saved parameters: /kaggle/working/runs/test_inference/trajectory_true_parameters.json\n",
      "\n",
      "Generating comparison plots...\n",
      "Comparison plot saved to: /kaggle/working/runs/test_inference/comparison_plot.png\n",
      "\n",
      "Computing metrics...\n",
      "Saved metrics: /kaggle/working/runs/test_inference/metrics.json\n",
      "\n",
      "============================================================\n",
      "INFERENCE RESULTS\n",
      "============================================================\n",
      "Position RMSE:  0.377500\n",
      "Position MAE:   0.310590\n",
      "Velocity MSE:   5.216902\n",
      "\n",
      "Energy drift (true): 0.000%\n",
      "Energy drift (pred): 6.525%\n",
      "============================================================\n",
      "\n",
      "All results saved to: /kaggle/working/runs/test_inference\n"
     ]
    }
   ],
   "source": [
    "t_start = 0\n",
    "t_end = 1\n",
    "num_points = 1000\n",
    "theta1 = 0.5\n",
    "theta2 = 0.2\n",
    "omega1 = 0\n",
    "omega2 = 0\n",
    "checkpoint = f\"{base_path}/runs/run_20260112_152535/checkpoints/best_model.pth\"\n",
    "output_dir = f\"{base_path}/runs/test_inference\"\n",
    "\n",
    "arg_list = [\n",
    "    f\"{checkpoint}\",\n",
    "    f\"--output-dir {output_dir}\",\n",
    "    f\"--t-start {t_start}\",\n",
    "    f\"--t-end {t_end}\",\n",
    "    f\"--omega1 {omega1}\",\n",
    "    f\"--omega2 {omega2}\",\n",
    "    f\"--theta1 {theta1}\",\n",
    "    f\"--theta2 {theta2}\",\n",
    "]\n",
    "args = \" \".join(arg_list)\n",
    "!python {project_root}/scripts/inference.py {args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64aae487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:56:59.786317Z",
     "iopub.status.busy": "2026-01-12T15:56:59.785795Z",
     "iopub.status.idle": "2026-01-12T15:56:59.929153Z",
     "shell.execute_reply": "2026-01-12T15:56:59.928478Z",
     "shell.execute_reply.started": "2026-01-12T15:56:59.786282Z"
    },
    "papermill": {
     "duration": 0.123159,
     "end_time": "2026-01-10T12:29:16.776566",
     "exception": false,
     "start_time": "2026-01-10T12:29:16.653407",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: runs/ (stored 0%)\n",
      "updating: runs/test_inference/ (stored 0%)\n",
      "updating: runs/test_inference/trajectory_true.npz (deflated 11%)\n",
      "updating: runs/test_inference/trajectory_pinn.npz (deflated 24%)\n",
      "updating: runs/test_inference/trajectory_pinn_parameters.json (deflated 48%)\n",
      "updating: runs/test_inference/trajectory_true_parameters.json (deflated 48%)\n",
      "updating: runs/test_inference/metrics.json (deflated 48%)\n",
      "updating: runs/test_inference/comparison_plot.png (deflated 9%)\n",
      "  adding: runs/run_20260112_152535/ (stored 0%)\n",
      "  adding: runs/run_20260112_152535/metrics.csv (deflated 51%)\n",
      "  adding: runs/run_20260112_152535/test_results.txt (deflated 66%)\n",
      "  adding: runs/run_20260112_152535/checkpoints/ (stored 0%)\n",
      "  adding: runs/run_20260112_152535/checkpoints/best_model.pth (deflated 11%)\n",
      "  adding: runs/run_20260112_152535/events.out.tfevents.1768231537.2429de81f59c.221803.0 (deflated 67%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/runs.zip runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f24a4918-2ee8-4557-be9e-f1e77c397c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T15:23:49.824230Z",
     "iopub.status.busy": "2026-01-12T15:23:49.823564Z",
     "iopub.status.idle": "2026-01-12T15:23:49.940499Z",
     "shell.execute_reply": "2026-01-12T15:23:49.939505Z",
     "shell.execute_reply.started": "2026-01-12T15:23:49.824195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf runs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9214451,
     "sourceId": 14444996,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "double-pendulum-simulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.911358,
   "end_time": "2026-01-10T12:29:16.996031",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-10T12:28:30.084673",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
