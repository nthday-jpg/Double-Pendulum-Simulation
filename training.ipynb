{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14426279,"sourceType":"datasetVersion","datasetId":9214451}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7324d51e","cell_type":"code","source":"import sys\nimport os\n\n# Define the absolute working directory\nbase_path = '/kaggle/working'\nproject_name = 'Double-Pendulum-Simulation'\nproject_root = os.path.join(base_path, project_name)\n\n# 1. Clone or Pull\nif not os.path.exists(project_root):\n    os.chdir(base_path)\n    !git clone https://github.com/nthday-jpg/Double-Pendulum-Simulation.git\n    print(\"Repository cloned successfully!\")\nelse:\n    os.chdir(project_root)\n    !git pull\n    print(\"Repository updated successfully!\")\n\n# 2. Correctly set the Python Path\n# It is vital to add the absolute path to the project root\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n\nos.chdir(base_path)\n\n# 4. Imports\ntry:\n    import torch\n    from models.pinn import PINN\n    from training.trainer import Trainer\n    from data.dataset import get_dataloader\n    from utils.config import Config\n    print(\"All modules imported successfully!\")\nexcept ImportError as e:\n    print(f\"Import failed: {e}\")\n    print(f\"Current sys.path: {sys.path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T16:54:56.930333Z","iopub.execute_input":"2026-01-08T16:54:56.931046Z","iopub.status.idle":"2026-01-08T16:54:57.266047Z","shell.execute_reply.started":"2026-01-08T16:54:56.931000Z","shell.execute_reply":"2026-01-08T16:54:57.265348Z"}},"outputs":[{"name":"stdout","text":"Already up to date.\nRepository updated successfully!\nAll modules imported successfully!\n","output_type":"stream"}],"execution_count":6},{"id":"15e0d823-16eb-417d-9ff7-2b140bbc61f2","cell_type":"code","source":"cfg = Config(\n    hidden_dims=[64, 64],  \n    input_dim=1,\n    output_dim=2,\n    residual_type=\"lagrangian\",\n    t_max=5, t_min=0,\n    epochs=1000,\n    early_stopping_patience = 50,\n    batch_size = 128,\n    batch_size_collocation = 512,\n    use_compile=False\n)\n\ninput_path = \"/kaggle/input/double-pendulum\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T16:55:01.062596Z","iopub.execute_input":"2026-01-08T16:55:01.063155Z","iopub.status.idle":"2026-01-08T16:55:01.067302Z","shell.execute_reply.started":"2026-01-08T16:55:01.063124Z","shell.execute_reply":"2026-01-08T16:55:01.066606Z"}},"outputs":[],"execution_count":8},{"id":"8c837010","cell_type":"code","source":"from accelerate import notebook_launcher\ndef train_func(config):  \n    model = PINN(cfg)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n    data_loader, colloc_loader, val_loader = get_dataloader(\n        data_path=f\"{input_path}/trajectory_000.npz\",\n        parameters_path=f\"{input_path}/parameters_000.json\",\n        config=cfg\n    )\n    trainer = Trainer(\n        model=model,\n        config=cfg,\n        data_loader=data_loader,\n        collocation_loader=colloc_loader,\n        val_loader=val_loader,\n        optimizer=optimizer\n    )\n\n    trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T16:55:03.214375Z","iopub.execute_input":"2026-01-08T16:55:03.215098Z","iopub.status.idle":"2026-01-08T16:55:03.219579Z","shell.execute_reply.started":"2026-01-08T16:55:03.215067Z","shell.execute_reply":"2026-01-08T16:55:03.218803Z"}},"outputs":[],"execution_count":9},{"id":"32a1ca02-5cfe-440b-bf13-d906628ba992","cell_type":"code","source":"notebook_launcher(train_func, args=(cfg,), num_processes=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T16:55:05.826569Z","iopub.execute_input":"2026-01-08T16:55:05.827132Z","iopub.status.idle":"2026-01-08T16:55:12.064085Z","shell.execute_reply.started":"2026-01-08T16:55:05.827103Z","shell.execute_reply":"2026-01-08T16:55:12.062981Z"}},"outputs":[{"name":"stdout","text":"Launching training on 2 CUDAs.\nDataLoaders: data_bs=128, colloc_bs=512, workers=4DataLoaders: data_bs=128, colloc_bs=512, workers=4\n\n============================================================\nStarting training for 1000 epochs...\nDevice: cuda:0\nData batch: 128, Collocation batch: 512\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [64, 1], strides() = [1, 64]\nbucket_view.sizes() = [64, 1], strides() = [1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [64, 1], strides() = [1, 64]\nbucket_view.sizes() = [64, 1], strides() = [1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"  Processing data batch 10...\n\n============================================================\nERROR at epoch 1\nProcess rank: 0\nError type: ValueError\nError: too many values to unpack (expected 2)\nTraceback:\nTraceback (most recent call last):\n  File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 124, in train\n    avg_val_loss = self.evaluate(self.val_loader)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 262, in evaluate\n    t, state, point_type = batch  # Changed from t, state = batch\n    ^^^^^^^^\nValueError: too many values to unpack (expected 2)\n\n============================================================\n\n============================================================\nERROR at epoch 1\nProcess rank: 1\nError type: ValueError\nError: too many values to unpack (expected 2)\nTraceback:\nTraceback (most recent call last):\n  File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 124, in train\n    avg_val_loss = self.evaluate(self.val_loader)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 262, in evaluate\n    t, state, point_type = batch  # Changed from t, state = batch\n    ^^^^^^^^\nValueError: too many values to unpack (expected 2)\n\n============================================================\n\n\nSaving current model state...\nTraining complete. Logs saved to runs/run_20260108_165501\n","output_type":"stream"},{"name":"stderr","text":"W0108 16:55:11.919000 55 torch/multiprocessing/spawn.py:169] Terminating process 337 via signal SIGTERM\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] failed (exitcode: 1) local_rank: 1 (pid: 338) of fn: train_func (start_method: fork)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] Traceback (most recent call last):\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 692, in _poll\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     self._pc.join(-1)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/usr/local/lib/python3.12/dist-packages/torch/multiprocessing/spawn.py\", line 215, in join\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     raise ProcessRaisedException(msg, error_index, failed_process.pid)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] torch.multiprocessing.spawn.ProcessRaisedException: \nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] \nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] -- Process 1 terminated with the following error:\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] Traceback (most recent call last):\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/usr/local/lib/python3.12/dist-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     fn(i, *args)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 616, in _wrap\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     ret = record(fn)(*args_)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]           ^^^^^^^^^^^^^^^^^^\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     return f(*args, **kwargs)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]            ^^^^^^^^^^^^^^^^^^\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/tmp/ipykernel_55/2445852004.py\", line 20, in train_func\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     trainer.train()\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 124, in train\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     avg_val_loss = self.evaluate(self.val_loader)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]   File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 262, in evaluate\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     t, state, point_type = batch  # Changed from t, state = batch\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737]     ^^^^^^^^\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] ValueError: too many values to unpack (expected 2)\nE0108 16:55:12.053000 55 torch/distributed/elastic/multiprocessing/api.py:737] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/408589966.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnotebook_launcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/launchers.py\u001b[0m in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    245\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_torch_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                         \u001b[0mlaunch_config_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_line_prefix_template\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_line_prefix_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                     \u001b[0melastic_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLaunchConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlaunch_config_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProcessRaisedException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34mf\"Cannot re-initialize {device_type.upper()} in forked subprocess\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlaunch_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entrypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\u001b[0m in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# @record will copy the first error (root cause)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;31m# to the error file of the launcher process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             raise ChildFailedError(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentrypoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mfailures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\ntrain_func FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2026-01-08_16:55:11\n  host      : cf75323b4399\n  rank      : 1 (local_rank: 1)\n  exitcode  : 1 (pid: 338)\n  error_file: /tmp/torchelastic_alemeqyu/none_tyycu9nj/attempt_0/1/error.json\n  traceback : Traceback (most recent call last):\n    File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n      return f(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^\n    File \"/tmp/ipykernel_55/2445852004.py\", line 20, in train_func\n      trainer.train()\n    File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 124, in train\n      avg_val_loss = self.evaluate(self.val_loader)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 262, in evaluate\n      t, state, point_type = batch  # Changed from t, state = batch\n      ^^^^^^^^\n  ValueError: too many values to unpack (expected 2)\n  \n============================================================"],"ename":"ChildFailedError","evalue":"\n============================================================\ntrain_func FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2026-01-08_16:55:11\n  host      : cf75323b4399\n  rank      : 1 (local_rank: 1)\n  exitcode  : 1 (pid: 338)\n  error_file: /tmp/torchelastic_alemeqyu/none_tyycu9nj/attempt_0/1/error.json\n  traceback : Traceback (most recent call last):\n    File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n      return f(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^\n    File \"/tmp/ipykernel_55/2445852004.py\", line 20, in train_func\n      trainer.train()\n    File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 124, in train\n      avg_val_loss = self.evaluate(self.val_loader)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/kaggle/working/Double-Pendulum-Simulation/training/trainer.py\", line 262, in evaluate\n      t, state, point_type = batch  # Changed from t, state = batch\n      ^^^^^^^^\n  ValueError: too many values to unpack (expected 2)\n  \n============================================================","output_type":"error"}],"execution_count":10},{"id":"91a06c3d-f1a8-4590-babc-f133ba89243f","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d6696218-57a4-4b67-8ed7-1e8088e3351c","cell_type":"code","source":"!zip -r /kaggle/working/runs ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T16:47:40.680539Z","iopub.status.idle":"2026-01-08T16:47:40.680802Z","shell.execute_reply.started":"2026-01-08T16:47:40.680682Z","shell.execute_reply":"2026-01-08T16:47:40.680699Z"}},"outputs":[],"execution_count":null}]}